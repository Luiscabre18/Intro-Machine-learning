{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5C058cUJbfB"
      },
      "source": [
        "# üß™ Parcial ‚Äì M√©todos Predictivos\n",
        "Completa las celdas con `TODO` y ejecuta `Runtime ‚Üí Run all` antes de entregar.\n",
        "\n",
        "## üéØ Instrucciones Generales\n",
        "- Este parcial est√° dividido en dos partes: teor√≠a (40 pts) y pr√°ctica (60 pts).\n",
        "- Documenta claramente tu c√≥digo y explica tus respuestas en celdas Markdown.\n",
        "- Al finalizar, exporta el notebook a PDF y entrega tambi√©n tus 5 slides con visualizaciones clave.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bf1ec3f"
      },
      "source": [
        "## <a id='parte-a'></a>üìù Parte¬†A ‚Äî Cuestionario Te√≥rico (40‚ÄØpts)\n",
        "Responde **brevemente** en las celdas Markdown que siguen a cada pregunta.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29324086"
      },
      "source": [
        "#### 1Ô∏è‚É£ **Variable objetivo (y)** ‚Äì Def√≠nela y da un ejemplo en este dataset.\n",
        "\n",
        "*Respuesta:* La variable objetivo (y) es la variable que queremos predecir o explicar utilizando las otras variables en el dataset (variables predictoras o caracter√≠sticas). Es el resultado que estamos interesados en modelar.\n",
        "\n",
        "En este dataset, aunque no se especifica el dataset en s√≠, si asumimos que este es un notebook para un parcial de M√©todos Predictivos, es muy probable que el objetivo sea predecir alguna caracter√≠stica o valor relacionado con los datos que se analizar√°n posteriormente. Un ejemplo t√≠pico en un contexto de modelado predictivo podr√≠a ser predecir el precio de una casa (si el dataset contiene datos de bienes ra√≠ces), predecir si un cliente comprar√° un producto (si son datos de marketing), o predecir si una transacci√≥n es fraudulenta (si son datos bancarios).\n",
        "\n",
        "Sin ver el dataset espec√≠fico, no podemos nombrar la variable objetivo exacta, pero *ser√≠a la columna o caracter√≠stica que se designe como el target para la predicci√≥n*.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00e18666"
      },
      "source": [
        "#### 2Ô∏è‚É£ Ordena las fases del *pipeline* de ML: `Modelado`, `Pre‚Äëprocesamiento`, `EDA`, `Evaluaci√≥n`, `Insight de negocio`.\n",
        "\n",
        "*Respuesta:*\n",
        "1.  **Insight de negocio:** Comprender el problema y definir el objetivo del proyecto desde una perspectiva de negocio.\n",
        "2.  **EDA (An√°lisis Exploratorio de Datos):** Entender la naturaleza de los datos, identificar patrones iniciales, anomal√≠as y relaciones entre variables.\n",
        "3.  **Pre-procesamiento:** Limpiar, transformar y preparar los datos para que sean adecuados para el modelado. Esto incluye manejo de valores faltantes, codificaci√≥n de variables categ√≥ricas, escalado, etc.\n",
        "4.  **Modelado:** Seleccionar y entrenar uno o varios modelos predictivos utilizando los datos pre-procesados.\n",
        "5.  **Evaluaci√≥n:** Medir el rendimiento del modelo entrenado utilizando m√©tricas apropiadas y datos de prueba independientes para evaluar qu√© tan bien generaliza a datos no vistos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "910a8986"
      },
      "source": [
        "#### 3Ô∏è‚É£ Para un problema de **clases desbalanceadas**, ¬øqu√© m√©trica priorizar√≠as y por qu√©?\n",
        "\n",
        "*Respuesta:* Para detectar el *overfitting* en la pr√°ctica, se utilizan principalmente las siguientes t√©cnicas:\n",
        "\n",
        "1.  **Divisi√≥n de Datos (Train/Test Split):** La forma m√°s com√∫n es dividir el conjunto de datos en al menos dos partes: un conjunto de entrenamiento (para ajustar el modelo) y un conjunto de prueba (para evaluar su rendimiento en datos no vistos). Si el rendimiento del modelo (medido con m√©tricas relevantes como precisi√≥n, error cuadr√°tico medio, F1-score, etc.) es muy alto en el conjunto de entrenamiento pero considerablemente bajo en el conjunto de prueba, es un fuerte indicio de *overfitting*.\n",
        "\n",
        "2.  **Validaci√≥n Cruzada (Cross-Validation):** Esta t√©cnica divide el conjunto de datos en m√∫ltiples \"folds\". El modelo se entrena en un subconjunto de folds y se eval√∫a en el fold restante. Este proceso se repite varias veces, utilizando diferentes folds como conjunto de prueba. Si el rendimiento promedio en los folds de prueba es significativamente menor que el rendimiento promedio en los folds de entrenamiento, sugiere *overfitting*.\n",
        "\n",
        "3.  **Curvas de Aprendizaje:** Graficar la m√©trica de rendimiento (ej. error) en funci√≥n del tama√±o del conjunto de entrenamiento o de la complejidad del modelo (ej. n√∫mero de √©pocas en redes neuronales). Una curva de error de entrenamiento que disminuye continuamente mientras que la curva de error de validaci√≥n (o prueba) se estanca o comienza a aumentar es un signo cl√°sico de *overfitting*.\n",
        "\n",
        "4.  **Comparaci√≥n de M√©tricas:** Observar la brecha entre las m√©tricas de rendimiento en el conjunto de entrenamiento y el conjunto de prueba. Una gran diferencia (mayor rendimiento en entrenamiento) indica sobreajuste.\n",
        "\n",
        "5.  **Inspecci√≥n del Modelo:** Para algunos modelos, como √°rboles de decisi√≥n, se puede inspeccionar su complejidad (profundidad del √°rbol). Un √°rbol muy profundo y ramificado es propenso al sobreajuste.\n",
        "\n",
        "En resumen, la detecci√≥n pr√°ctica del *overfitting* se basa en evaluar el rendimiento del modelo en datos que no ha visto durante el entrenamiento y comparar ese rendimiento con el obtenido en los datos de entrenamiento. Un rendimiento significativamente inferior en datos nuevos es la se√±al principal.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4de30673"
      },
      "source": [
        "#### 4Ô∏è‚É£ Describe **overfitting** y c√≥mo lo detectar√≠as en la pr√°ctica.\n",
        "\n",
        "*Respuesta:*\n",
        "1.  **Monitorear el rendimiento en los conjuntos de entrenamiento y validaci√≥n/prueba:**\n",
        "    *   Divide tus datos en conjuntos de entrenamiento, validaci√≥n y prueba (o usa validaci√≥n cruzada).\n",
        "    *   Entrena tu modelo en el conjunto de entrenamiento.\n",
        "    *   Calcula la m√©trica de rendimiento (por ejemplo, precisi√≥n, error cuadr√°tico medio, F1-score) tanto en el conjunto de entrenamiento como en el conjunto de validaci√≥n (o prueba) despu√©s de cada √©poca o iteraci√≥n de entrenamiento (especialmente en modelos iterativos como redes neuronales).\n",
        "    *   **Detecci√≥n de Overfitting:** Si el rendimiento en el conjunto de entrenamiento sigue mejorando (la m√©trica aumenta o disminuye seg√∫n sea el caso, indicando un mejor ajuste) mientras que el rendimiento en el conjunto de validaci√≥n/prueba se estanca o **empieza a empeorar**, es un signo claro de overfitting. El modelo est√° memorizando el ruido del entrenamiento en lugar de aprender patrones generalizables.\n",
        "\n",
        "2.  **Validaci√≥n Cruzada (Cross-Validation):**\n",
        "    *   Divide el conjunto de entrenamiento en k \"folds\".\n",
        "    *   Entrena el modelo k veces, usando cada fold como conjunto de validaci√≥n una vez y el resto de los folds como conjunto de entrenamiento.\n",
        "    *   Calcula la m√©trica de rendimiento en cada fold de validaci√≥n.\n",
        "    *   **Detecci√≥n de Overfitting:** Si el modelo tiene un rendimiento muy alto en el conjunto de entrenamiento general (cuando se entrena en todos los datos menos el fold de validaci√≥n) pero la m√©trica de rendimiento promedio en los folds de validaci√≥n es significativamente m√°s baja, indica overfitting.\n",
        "\n",
        "3.  **Inspecci√≥n visual de curvas de aprendizaje:**\n",
        "    *   Grafica la m√©trica de rendimiento (por ejemplo, p√©rdida o accuracy) en funci√≥n de las √©pocas de entrenamiento. Tendr√°s una curva para el conjunto de entrenamiento y otra para el conjunto de validaci√≥n.\n",
        "    *   **Detecci√≥n de Overfitting:** Si la curva de entrenamiento contin√∫a disminuyendo o aumentando (mejorando) mientras que la curva de validaci√≥n se estabiliza y luego comienza a aumentar o disminuir (empeorando), las curvas se \"separan\". Esta divergencia es un indicio visual de overfitting.\n",
        "\n",
        "4.  **Comparaci√≥n con modelos m√°s simples:**\n",
        "    *   Entrena tambi√©n modelos m√°s simples (con menos par√°metros o restricciones de regularizaci√≥n).\n",
        "    *   **Detecci√≥n de Overfitting:** Si tu modelo complejo tiene un rendimiento significativamente mejor en el conjunto de entrenamiento que los modelos simples, pero no logra superar o incluso tiene un rendimiento peor que los modelos simples en el conjunto de validaci√≥n/prueba, es probable que est√© sufriendo de overfitting.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3fbcf52"
      },
      "source": [
        "#### 5Ô∏è‚É£ Completa: *K‚Äëmeans es un algoritmo de _________ porque ________.*\n",
        "\n",
        "*Respuesta:*K MEANS ES UN clustering aprendizaje no supervisado** porque **no requiere etiquetas o variables objetivo predefinidas en los datos de entrenamiento; su objetivo es encontrar estructuras inherentes (grupos o cl√∫steres) en los datos bas√°ndose en la similitud entre puntos.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "033b889a"
      },
      "source": [
        "#### 7Ô∏è‚É£ En **regresi√≥n**, ¬øc√≥mo es la variable objetivo? (cualitativa, cuantitativa, binaria‚Ä¶).\n",
        "\n",
        "*Respuesta:* En regresi√≥n, la variable objetivo es **cuantitativa**. Esto significa que toma valores num√©ricos continuos o discretos que representan una cantidad, como el precio de una casa, la temperatura, el salario, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aea04580"
      },
      "source": [
        "#### 8Ô∏è‚É£ Menciona 2 t√©cnicas comunes de **pre‚Äëprocesamiento de texto**.\n",
        "\n",
        "*Respuesta:*\n",
        "-   **Tokenizaci√≥n:** Dividir el texto en unidades m√°s peque√±as llamadas tokens (generalmente palabras o frases). Esto es el primer paso para analizar el texto.\n",
        "-   **Eliminaci√≥n de Stop Words:** Eliminar palabras muy comunes que no aportan mucho significado al an√°lisis (como \"el\", \"la\", \"un\", \"y\", etc.).\n",
        "-   **Stemming o Lematizaci√≥n:** Reducir las palabras a su ra√≠z o lema para agrupar formas flexionadas de una palabra. El stemming es m√°s simple (corta sufijos), la lematizaci√≥n es m√°s sofisticada (usa vocabulario y an√°lisis morfol√≥gico).\n",
        "-   **Normalizaci√≥n del Texto:** Convertir el texto a un formato consistente (ej. pasar todo a min√∫sculas, eliminar puntuaci√≥n, manejar caracteres especiales).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dc106a4"
      },
      "source": [
        "#### 9Ô∏è‚É£ ¬øQu√© representa el par√°metro *k* en K‚Äëmeans y qu√© ocurre si es muy grande?\n",
        "\n",
        "*Respuesta:*\n",
        "1.  **Fragmentaci√≥n de Cl√∫steres:** Los grupos naturales existentes se pueden dividir en m√∫ltiples cl√∫steres m√°s peque√±os, incluso si no hay una justificaci√≥n inherente en los datos para tal divisi√≥n. Cada cl√∫ster podr√≠a contener muy pocos puntos.\n",
        "2.  **Sensibilidad al Ruido y Outliers:** El algoritmo se vuelve m√°s sensible a puntos de datos individuales (ruido o *outliers*), ya que estos puntos pueden terminar formando sus propios cl√∫steres (especialmente si *k* se acerca al n√∫mero de puntos).\n",
        "3.  **P√©rdida de Interpretaci√≥n:** Los cl√∫steres resultantes pueden no tener un significado claro o √∫til desde la perspectiva del dominio del problema, ya que representan particiones muy finas o arbitrarias de los datos.\n",
        "4.  **Mayor Costo Computacional:** Aunque el K-means es relativamente eficiente, un *k* muy grande aumenta el costo computacional, ya que el algoritmo necesita calcular y actualizar *k* centroides en cada iteraci√≥n.\n",
        "5.  **Problemas de Convergencia y Estabilidad:** Puede ser m√°s dif√≠cil que el algoritmo converja a una soluci√≥n estable o que las soluciones var√≠en mucho con diferentes inicializaciones, ya que hay muchas m√°s formas de particionar los datos en un gran n√∫mero de grupos peque√±os.\n",
        "6.  **Overfitting (en un sentido de clustering):** Aunque no es overfitting en el sentido de modelos predictivos supervisados, un *k* muy grande puede llevar a que el algoritmo se ajuste demasiado a las particularidades espec√≠ficas (y quiz√°s ruidosas) del conjunto de datos particular, en lugar de capturar la estructura general de los datos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86dcdc0c"
      },
      "source": [
        "#### üîü Define brevemente un **embedding** en NLP y su utilidad.\n",
        "\n",
        "*Respuesta:* <!-- TODO -->\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/javierherrera1996/IntroMachineLearning/raw/refs/heads/main/TercerCorte/amazon.csv.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKgMhF70KOgs",
        "outputId": "26f538e6-9cdd-4a2f-cd55-4e539b4d191e"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-04 21:51:44--  https://github.com/javierherrera1996/IntroMachineLearning/raw/refs/heads/main/TercerCorte/amazon.csv.zip\n",
            "Resolving github.com (github.com)... 20.27.177.113\n",
            "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/javierherrera1996/IntroMachineLearning/refs/heads/main/TercerCorte/amazon.csv.zip [following]\n",
            "--2025-06-04 21:51:44--  https://raw.githubusercontent.com/javierherrera1996/IntroMachineLearning/refs/heads/main/TercerCorte/amazon.csv.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2043633 (1.9M) [application/zip]\n",
            "Saving to: ‚Äòamazon.csv.zip.1‚Äô\n",
            "\n",
            "amazon.csv.zip.1    100%[===================>]   1.95M  6.20MB/s    in 0.3s    \n",
            "\n",
            "2025-06-04 21:51:45 (6.20 MB/s) - ‚Äòamazon.csv.zip.1‚Äô saved [2043633/2043633]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip amazon.csv.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlyjvkJ5KSZJ",
        "outputId": "a1eb6d35-2fe9-44af-8b72-08edd0e3a0c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  amazon.csv.zip\n",
            "replace amazon.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xM7_2IEWJbfO"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "import warnings, random\n",
        "warnings.filterwarnings('ignore')\n",
        "random.seed(42)\n",
        "np.random.seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gF4aSmyJbfP"
      },
      "source": [
        "### 2. Carga de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIkhxBFLJbfQ"
      },
      "source": [
        "# Reemplaza con la ruta correcta de tu archivo CSV si lo subes a Colab\n",
        "df = pd.read_csv('amazon.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1zpzVwFJbfQ"
      },
      "source": [
        "### 3. Limpieza y Feature Engineering\n",
        "\n",
        "\n",
        "*   Tome `review_content` para crear una columna text\n",
        "\n",
        "*   Haga una limpieza de rating:\n",
        "```\n",
        "df['col'] = df['col'].str.replace(',', '.').str.strip()\n",
        "df['col'] = df['col'].str.replace('|', '0').str.strip()\n",
        "df['col'] = df['col'].astype(float)\n",
        "```\n",
        "*   Haga una limpieza de `discounted_price`\n",
        "\n",
        "\n",
        "```\n",
        "  df['col'] = df['col'].str.replace('.', '', regex=False).str.replace(',', '.', regex=False)\n",
        "  df['col'] = df['col'].replace('‚Çπ', '', regex=True).astype(float)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "*   Haga una limpieza de `actual_price`\n",
        "\n",
        "```\n",
        "df['col'] = df['col'].str.replace('.', '', regex=False).str.replace(',', '.', regex=False)\n",
        "df['col'] = df['col'].replace('‚Çπ', '', regex=True)\n",
        "df['col'] = df['col'].astype(float)\n",
        "```\n",
        "\n",
        "\n",
        "*   Cree la variable `positive` donde `ranting` se mayor a 4:\n",
        "```\n",
        "df['col1'] = df['col2'].apply(lambda x: 1 if x >= 4 else 0)\n",
        "```\n",
        "\n",
        "*   Con `discount_percentage` donde `ranting` se mayor a 4:\n",
        "```\n",
        "df['col'] = df['col'].replace('%', '', regex=True).astype(float)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Tome review_content para crear una columna text\n",
        "\n",
        "df['text'] = df['review_content']"
      ],
      "metadata": {
        "id": "jJ_Pk_AH4o28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Haga una limpieza de rating:\n",
        "\n",
        "df['rating'] = df['rating'].str.replace(',', '.').str.strip()\n",
        "df['rating'] = df['rating'].str.replace('|', '0').str.strip()\n",
        "df['rating'] = df['rating'].astype(float)"
      ],
      "metadata": {
        "id": "_6T03Kyp4vAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Haga una limpieza de discounted_price\n",
        "\n",
        "df['discounted_price'] = df['discounted_price'].str.replace('.', '', regex=False).str.replace(',', '.', regex=False)\n",
        "df['discounted_price'] = df['discounted_price'].replace('‚Çπ', '', regex=True).astype(float)\n"
      ],
      "metadata": {
        "id": "IyBUQttu4zmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Haga una limpieza de actual_price\n",
        "\n",
        "df['actual_price'] = df['actual_price'].str.replace('.', '', regex=False).str.replace(',', '.', regex=False)\n",
        "df['actual_price'] = df['actual_price'].replace('‚Çπ', '', regex=True)\n",
        "df['actual_price'] = df['actual_price'].astype(float)\n",
        "\n",
        "df['positive'] = df['rating'].apply(lambda x: 1 if x >= 4 else 0)\n",
        "\n",
        "df['discount_percentage'] = df['discount_percentage'].replace('%', '', regex=True).astype(float)"
      ],
      "metadata": {
        "id": "zJxNHCxS439b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['positive'] = df['rating'].apply(lambda x: 1 if x >= 4 else 0)"
      ],
      "metadata": {
        "id": "ndl-opUc49iz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['discount_percentage'] = df.apply(lambda row: row['discount_percentage'] if row['rating'] >= 4 else 0, axis=1)"
      ],
      "metadata": {
        "id": "fgnA2YHE5Dv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud"
      ],
      "metadata": {
        "id": "kSYCsWI-QsM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from textblob import TextBlob\n",
        "import pandas as pd\n",
        "import re\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "8FBgW2i_RLTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bciCmuVuJbfN"
      },
      "source": [
        "## üíª Parte B ‚Äì Pr√°ctica (60 pts)\n",
        "### 1. Setup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Realize dos WorldClouds uno con reviews positivos y otro con negativos y haga un grafico de barras comaparado por los 10 mas comunes."
      ],
      "metadata": {
        "id": "UVWq1S-un5XI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def limpiar_texto(texto):\n",
        "    texto = texto.lower()\n",
        "    texto = re.sub(r'[^\\w\\s]', '', texto)\n",
        "    palabras = texto.split()\n",
        "    palabras = [palabra for palabra in palabras if palabra not in stop_words]\n",
        "    return palabras"
      ],
      "metadata": {
        "id": "zHlFFi3mRau6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def contar_palabras(texto):\n",
        "    palabras = limpiar_texto(texto)\n",
        "    return Counter(palabras)"
      ],
      "metadata": {
        "id": "GF-LzohLRdtv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkNwzI74JbfR"
      },
      "source": [
        "### 4. An√°lisis Exploratorio de Datos (EDA)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: An√°lisis Exploratorio de Datos (EDA)\n",
        "\n",
        "# TODO: Generar WorldClouds para reviews positivos y negativos\n",
        "#\n",
        "# Separa los reviews en positivos y negativos\n",
        "positive_reviews = df[df['positive'] == 1]['text']\n",
        "negative_reviews = df[df['positive'] == 0]['text']\n",
        "\n",
        "# Combina todos los textos de reviews positivos y negativos\n",
        "all_positive_text = \" \".join(positive_reviews.dropna())\n",
        "all_negative_text = \" \".join(negative_reviews.dropna())\n",
        "\n",
        "# Crea WordCloud para reviews positivos\n",
        "wordcloud_positive = WordCloud(width=800, height=400, background_color='white').generate(all_positive_text)\n",
        "\n",
        "# Crea WordCloud para reviews negativos\n",
        "wordcloud_negative = WordCloud(width=800, height=400, background_color='white').generate(all_negative_text)\n",
        "\n",
        "# Visualiza los WordClouds\n",
        "plt.figure(figsize=(20, 10))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(wordcloud_positive, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title('Word Cloud - Reviews Positivos')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(wordcloud_negative, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title('Word Cloud - Reviews Negativos')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BtQO5a0s5ijj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6TCp_C-JbfS"
      },
      "source": [
        "### 5. Clasificaci√≥n Supervisada ‚Äì Regresi√≥n Log√≠stica (25 pts)\n",
        "\n",
        "\n",
        "*   Haga una regresion logistica de postive vs text\n",
        "*   Muestre los resultados en una matriz de confusion\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oV-qhmsjJbfS"
      },
      "source": [
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['positive'], test_size=0.2, random_state=42)\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(stop_words=list(stop_words), max_features=5000)), # Usar stop words descargadas\n",
        "    ('logreg', LogisticRegression())\n",
        "])\n",
        "\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Muestre los resultados en una matriz de confusion\n",
        "\n",
        "# Calcular y visualizar la matriz de confusi√≥n\n",
        "cm = ConfusionMatrixDisplay.from_estimator(pipeline, X_test, y_test, display_labels=['Negative', 'Positive'], cmap=plt.cm.Blues)\n",
        "plt.title('Matriz de Confusi√≥n - Regresi√≥n Log√≠stica')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2ZKj8U_75w7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keiDLchMJbfS"
      },
      "source": [
        "### 6. Agrupamiento K-Means ‚Äì No Supervisado (20 pts)\n",
        "\n",
        "\n",
        "*   Cree una variable cluster usando un modelo de clustering\n",
        "\n",
        "*   Como podria nombrar los clusters usando las otras variables\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tfidf_vectorizer_kmeans = TfidfVectorizer(stop_words=list(stop_words), max_features=5000)\n",
        "X_tfidf_kmeans = tfidf_vectorizer_kmeans.fit_transform(df['text'].dropna()) # Usar el texto completo para clustering, manejando NaNs\n",
        "\n",
        "k = 3 # Ejemplo: Elegimos 3 clusters\n",
        "\n",
        "# Inicializar y entrenar el modelo K-Means\n",
        "kmeans_model = KMeans(n_clusters=k, random_state=42, n_init=10) # A√±adir n_init para evitar warning\n",
        "# Aplicar K-Means al texto vectorizado\n",
        "df['cluster'] = -1 # Inicializar con un valor por defecto para las filas con NaN en texto\n",
        "df.loc[df['text'].dropna().index, 'cluster'] = kmeans_model.fit_predict(X_tfidf_kmeans)\n",
        "\n",
        "# Mostrar la distribuci√≥n de los clusters (solo para las filas donde se aplic√≥ K-Means)\n",
        "print(\"\\nDistribuci√≥n de los cl√∫steres:\")\n",
        "print(df['cluster'].value_counts())\n",
        "\n",
        "print(\"\\nEstad√≠sticas por Cl√∫ster:\")\n",
        "print(df.groupby('cluster')[['rating', 'discounted_price', 'actual_price', 'discount_percentage', 'positive']].mean())\n",
        "\n",
        "# Ejemplo de c√≥mo ver la distribuci√≥n de la variable 'positive' por cl√∫ster\n",
        "print(\"\\nDistribuci√≥n de 'positive' por Cl√∫ster:\")\n",
        "print(df.groupby('cluster')['positive'].value_counts(normalize=True).unstack().fillna(0))\n",
        "\n",
        "# Bas√°ndose en estas estad√≠sticas y en las palabras clave encontradas en cada cl√∫ster,\n",
        "# se asignar√≠an nombres descriptivos a cada grupo (ej. \"Cl√∫ster de Alta Satisfacci√≥n\", \"Cl√∫ster de Preocupaciones sobre el Precio\", etc.)."
      ],
      "metadata": {
        "id": "vlSDjYLSpBd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Como podria nombrar los clusters usando las otras variables\n",
        "\n",
        "# A√±adir el an√°lisis de palabras clave por cl√∫ster\n",
        "print(\"\\nPalabras clave (ejemplo) por Cl√∫ster:\")\n",
        "\n",
        "# Obtener los centroides de los cl√∫steres en el espacio TF-IDF\n",
        "cluster_centroids = kmeans_model.cluster_centers_\n",
        "\n",
        "# Obtener los nombres de las caracter√≠sticas (palabras) del vectorizador TF-IDF\n",
        "terms = tfidf_vectorizer_kmeans.get_feature_names_out()\n",
        "\n",
        "# Para cada cl√∫ster, encontrar las palabras con los valores de centroide m√°s altos\n",
        "num_top_words = 15 # N√∫mero de palabras clave a mostrar por cl√∫ster\n",
        "\n",
        "for i in range(k):\n",
        "    print(f\"Cl√∫ster {i}:\")\n",
        "    # Ordenar los t√©rminos por el valor del centroide en este cl√∫ster\n",
        "    centroid_features = cluster_centroids[i].argsort()[-num_top_words:][::-1]\n",
        "    top_words = [terms[ind] for ind in centroid_features]\n",
        "    print(\"  \" + \", \".join(top_words))\n"
      ],
      "metadata": {
        "id": "PuufdXaQ57tb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGQrv_gIJbfT"
      },
      "source": [
        "### 7. Insight & Recomendaciones (15 pts)\n",
        "Escribe tu an√°lisis aqu√≠:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3b2uv6-JbfT"
      },
      "source": [
        "TODO: Relaciona errores del modelo con los clusters y propone acciones de negocio."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt:  Relaciona errores del modelo con los clusters y propone acciones de negocio.\n",
        "\n",
        "# Analizar los errores del modelo de Regresi√≥n Log√≠stica en relaci√≥n con los cl√∫steres\n",
        "# Primero, necesitamos identificar las predicciones incorrectas del modelo de clasificaci√≥n.\n",
        "\n",
        "# Asegurarnos de que las predicciones y los cl√∫steres est√©n alineados con el DataFrame original\n",
        "# K-Means se ajust√≥ solo a las filas sin NaN en 'text'. Necesitamos manejar esto.\n",
        "# Creamos una columna temporal para las predicciones en el DataFrame original\n",
        "df['predicted_positive'] = -1 # Inicializamos con un valor diferente\n",
        "# Obtenemos las predicciones solo para las filas donde X_test corresponde\n",
        "# Esto requiere mapear de nuevo al √≠ndice original o usar el DataFrame de prueba si se conserv√≥ el √≠ndice.\n",
        "# Si X_test es solo una serie de texto, es m√°s f√°cil predecir sobre todo el df donde text no es NaN\n",
        "# y luego filtrar por el √≠ndice de X_test.\n",
        "\n",
        "# Volvemos a predecir para todas las filas con texto no nulo para alinear con los cl√∫steres\n",
        "# que tambi√©n se calcularon sobre filas no nulas.\n",
        "df_non_null_text = df.dropna(subset=['text'])\n",
        "X_non_null_text = df_non_null_text['text']\n",
        "y_non_null_true = df_non_null_text['positive']\n",
        "\n",
        "# Predict usando el pipeline entrenado\n",
        "y_non_null_pred = pipeline.predict(X_non_null_text)\n",
        "\n",
        "# A√±adir predicciones y errores (indicador booleano) al DataFrame original\n",
        "df['predicted_positive'] = -1 # Reset\n",
        "df['is_error'] = False # Reset\n",
        "\n",
        "# Actualizar solo las filas con texto no nulo\n",
        "df.loc[df_non_null_text.index, 'predicted_positive'] = y_non_null_pred\n",
        "df.loc[df_non_null_text.index, 'is_error'] = (df_non_null_text['positive'].values != y_non_null_pred)\n",
        "\n",
        "# Ahora, analiza la distribuci√≥n de los errores por cl√∫ster\n",
        "print(\"\\nAn√°lisis de Errores por Cl√∫ster:\")\n",
        "\n",
        "# Estad√≠sticas de errores por cl√∫ster (contar cu√°ntos errores hay en cada cl√∫ster)\n",
        "# Filtramos las filas donde el cl√∫ster fue asignado (-1 indica que el texto era NaN)\n",
        "df_clustered_errors = df[(df['cluster'] != -1) & (df['predicted_positive'] != -1)]\n",
        "\n",
        "if not df_clustered_errors.empty:\n",
        "    error_distribution = df_clustered_errors.groupby('cluster')['is_error'].value_counts(normalize=True).unstack().fillna(0)\n",
        "    print(\"\\nProporci√≥n de errores por Cl√∫ster:\")\n",
        "    print(error_distribution)\n",
        "\n",
        "    # Opcional: Contar el n√∫mero total de errores por cl√∫ster\n",
        "    total_errors_per_cluster = df_clustered_errors[df_clustered_errors['is_error']].groupby('cluster').size()\n",
        "    print(\"\\nN√∫mero total de errores por Cl√∫ster:\")\n",
        "    print(total_errors_per_cluster)\n",
        "\n",
        "    # Identificar el tipo de error: Falso Positivo (FP) o Falso Negativo (FN)\n",
        "    # FP: Real Negativo (0), Predicho Positivo (1)\n",
        "    # FN: Real Positivo (1), Predicho Negativo (0)\n",
        "\n",
        "    df_errors = df_clustered_errors[df_clustered_errors['is_error']].copy()\n",
        "    df_errors['error_type'] = 'Other'\n",
        "    df_errors.loc[(df_errors['positive'] == 0) & (df_errors['predicted_positive'] == 1), 'error_type'] = 'False Positive'\n",
        "    df_errors.loc[(df_errors['positive'] == 1) & (df_errors['predicted_positive'] == 0), 'error_type'] = 'False Negative'\n",
        "\n",
        "    print(\"\\nDistribuci√≥n del Tipo de Error por Cl√∫ster:\")\n",
        "    if not df_errors.empty:\n",
        "        error_type_distribution = df_errors.groupby('cluster')['error_type'].value_counts(normalize=True).unstack().fillna(0)\n",
        "        print(error_type_distribution)\n",
        "    else:\n",
        "        print(\"No hay errores para analizar en los cl√∫steres.\")\n",
        "\n",
        "    # An√°lisis de Insight y Recomendaciones de Negocio\n",
        "    print(\"\\n--- Insight y Recomendaciones de Negocio ---\")\n",
        "\n",
        "    # Conectar errores espec√≠ficos en ciertos cl√∫steres con caracter√≠sticas de esos cl√∫steres\n",
        "    # y proponer acciones.\n",
        "\n",
        "    # Basado en el an√°lisis de las estad√≠sticas por cl√∫ster y la distribuci√≥n de errores:\n",
        "\n",
        "    for cluster_id in sorted(df_clustered_errors['cluster'].unique()):\n",
        "        print(f\"\\nAn√°lisis para Cl√∫ster {cluster_id}:\")\n",
        "        cluster_stats = df.loc[df['cluster'] == cluster_id, ['rating', 'discounted_price', 'actual_price', 'discount_percentage', 'positive']].mean()\n",
        "        print(f\"  Estad√≠sticas promedio: {cluster_stats.to_dict()}\")\n",
        "\n",
        "        # Analizar la proporci√≥n y tipo de errores en este cl√∫ster\n",
        "        if cluster_id in error_distribution.index:\n",
        "             cluster_error_proportion = error_distribution.loc[cluster_id, True]\n",
        "             print(f\"  Proporci√≥n de errores: {cluster_error_proportion:.2f}\")\n",
        "\n",
        "             if cluster_id in error_type_distribution.index:\n",
        "                 cluster_error_types = error_type_distribution.loc[cluster_id].to_dict()\n",
        "                 print(f\"  Tipos de error (%): {cluster_error_types}\")\n",
        "\n",
        "                 # Proponer acciones basadas en el tipo de error predominante y las caracter√≠sticas del cl√∫ster\n",
        "                 print(\"  Acciones de Negocio Sugeridas:\")\n",
        "\n",
        "                 if 'False Negative' in cluster_error_types and cluster_error_types['False Negative'] > cluster_error_types.get('False Positive', 0):\n",
        "                     # Predominan los Falsos Negativos: El modelo predice negativo, pero la review es positiva.\n",
        "                     # Esto significa que estamos perdiendo oportunidades de identificar satisfacci√≥n.\n",
        "                     print(f\"    - Predominan los Falsos Negativos. Este cl√∫ster tiene reviews que el modelo etiqueta como negativos pero son positivos.\")\n",
        "                     print(f\"    - Posiblemente las reviews positivas en este cl√∫ster contienen lenguaje sutil o jerga que el modelo no capta.\")\n",
        "                     print(f\"    - Acci√≥n: Investigar las reviews mal clasificadas en este cl√∫ster (Reviews con positive=1 y predicted_positive=0).\")\n",
        "                     print(f\"    - Acci√≥n: Mejorar el pre-procesamiento de texto o considerar modelos m√°s complejos (ej. transformers) para captar matices.\")\n",
        "                     print(f\"    - Acci√≥n: Si este cl√∫ster tiene caracter√≠sticas de precios o descuentos particulares, explorar si hay un sesgo relacionado con el valor percibido que afecta la forma en que se expresan los comentarios positivos.\")\n",
        "                     print(f\"    - Acci√≥n: Identificar qu√© caracter√≠sticas de los productos o la experiencia de compra son apreciadas en este cl√∫ster (basado en palabras clave) para potenciar campa√±as de marketing dirigidas.\")\n",
        "\n",
        "\n",
        "                 elif 'False Positive' in cluster_error_types and cluster_error_types['False Positive'] > cluster_error_types.get('False Negative', 0):\n",
        "                      # Predominan los Falsos Positivos: El modelo predice positivo, pero la review es negativa.\n",
        "                      # Esto significa que estamos identificando satisfacci√≥n donde no la hay, lo cual puede llevar a ignorar problemas.\n",
        "                      print(f\"    - Predominan los Falsos Positivos. Este cl√∫ster contiene reviews que el modelo clasifica como positivos pero que en realidad son negativos.\")\n",
        "                      print(f\"    - Las reviews en este cl√∫ster pueden contener sarcasmo, cr√≠ticas constructivas envueltas en lenguaje positivo, o menciones de aspectos negativos que el modelo pasa por alto.\")\n",
        "                      print(f\"    - Acci√≥n: Analizar las reviews mal clasificadas en este cl√∫ster (Reviews con positive=0 y predicted_positive=1) para entender el lenguaje y las quejas.\")\n",
        "                      print(f\"    - Acci√≥n: Refinar las caracter√≠sticas de texto (ej. n-gramas m√°s amplios, an√°lisis de sentimiento m√°s profundo) o usar t√©cnicas de detecci√≥n de iron√≠a/sarcasmo.\")\n",
        "                      print(f\"    - Acci√≥n: Si este cl√∫ster muestra patrones en precio o descuento, podr√≠a indicar que incluso con ofertas, hay problemas subyacentes que generan insatisfacci√≥n.\")\n",
        "                      print(f\"    - Acci√≥n: Identificar las quejas recurrentes en este cl√∫ster (basado en palabras clave y an√°lisis manual de errores) para informar mejoras de producto o servicio.\")\n",
        "\n",
        "\n",
        "                 else: # Similar proporci√≥n de FP y FN o pocos errores\n",
        "                      print(f\"    - El modelo tiene un rendimiento equilibrado de errores (o pocos errores) en este cl√∫ster.\")\n",
        "                      print(f\"    - Acci√≥n: Continuar monitoreando el rendimiento en este grupo.\")\n",
        "                      print(f\"    - Acci√≥n: Si el cl√∫ster representa un segmento de cliente o producto importante, investigar las pocas reviews mal clasificadas para entender casos at√≠picos.\")\n",
        "\n",
        "             else:\n",
        "                 print(\"  No hay tipos de error registrados para este cl√∫ster (posiblemente 0 errores).\")\n",
        "        else:\n",
        "            print(\"  Este cl√∫ster no tuvo errores en el conjunto de prueba con texto no nulo.\")\n",
        "\n",
        "    # Recomendaciones generales basadas en los cl√∫steres\n",
        "    print(\"\\nRecomendaciones Generales Basadas en los Cl√∫steres:\")\n",
        "    # Por ejemplo, si el Cl√∫ster 0 tiene rating promedio bajo y descuentos altos\n",
        "    # Si el Cl√∫ster 1 tiene rating alto y precios altos\n",
        "    # Si el Cl√∫ster 2 tiene rating medio y descuentos medios\n",
        "\n",
        "    # Ejemplo de recomendaciones hipot√©ticas basadas en la salida del clustering y errores:\n",
        "    # Reemplaza con el an√°lisis espec√≠fico de TUS cl√∫steres\n",
        "    print(\"\\nEjemplo de Interpretaci√≥n y Acci√≥n (Basado en la salida anterior):\")\n",
        "\n",
        "    # Suponiendo (ejemplo) que:\n",
        "    # Cl√∫ster 0: Bajo rating promedio, alto descuento. Predominan FP (modelo predice positivo en reviews negativas). Palabras clave: \"precio\", \"descuento\", \"barato\".\n",
        "    # Cl√∫ster 1: Alto rating promedio, precio alto. Predominan FN (modelo predice negativo en reviews positivas). Palabras clave: \"calidad\", \"excelente\", \"recomendado\".\n",
        "    # Cl√∫ster 2: Rating medio, precio medio. Errores m√°s equilibrados. Palabras clave: \"funciona\", \"bien\", \"producto\".\n",
        "\n",
        "    print(\"\\nInterpretaci√≥n Hipot√©tica de Cl√∫steres:\")\n",
        "    print(\"- Cl√∫ster 0 ('Clientes Sensibles al Precio con Quejas'): Predominan reviews negativas a pesar de altos descuentos. El modelo falla (FP) al clasificar algunas quejas como positivas. Indica que el precio bajo no compensa problemas subyacentes.\")\n",
        "    print(\"- Cl√∫ster 1 ('Clientes Satisfechos de Alta Gana'): Reviews muy positivas, a menudo sobre productos caros. El modelo a veces falla (FN) al identificar esta satisfacci√≥n, quiz√°s por lenguaje muy descriptivo o espec√≠fico.\")\n",
        "    print(\"- Cl√∫ster 2 ('Clientes Promedio'): Experiencias mixtas o neutras. El modelo tiene un rendimiento de errores m√°s balanceado.\")\n",
        "\n",
        "    print(\"\\nRecomendaciones de Negocio Hipot√©ticas:\")\n",
        "    print(\"- **Para el Cl√∫ster 0 ('Clientes Sensibles al Precio con Quejas'):**\")\n",
        "    print(\"  - Acci√≥n: No depender solo de descuentos para satisfacer a este grupo. Investigar y solucionar los problemas espec√≠ficos mencionados en sus reviews negativas (usando las palabras clave y revisando reviews mal clasificadas) incluso si compraron con descuento. La insatisfacci√≥n aqu√≠ es de mayor riesgo a pesar del precio.\")\n",
        "    print(\"  - Acci√≥n: Mejorar la calidad del producto/servicio para este segmento. Un precio bajo no justifica un producto deficiente a largo plazo.\")\n",
        "    print(\"- **Para el Cl√∫ster 1 ('Clientes Satisfechos de Alta Gama'):**\")\n",
        "    print(\"  - Acci√≥n: Identificar y destacar las caracter√≠sticas de los productos y la experiencia que generan alta satisfacci√≥n en este grupo (basado en sus palabras clave). Utilizar estas 'historias de √©xito' en marketing para atraer clientes similares.\")\n",
        "    print(\"  - Acci√≥n: Fomentar que estos clientes dejen reviews o testimonios, ya que representan el valor percibido de productos de mayor precio.\")\n",
        "    print(\"- **Para el Cl√∫ster 2 ('Clientes Promedio'):**\")\n",
        "    print(\"  - Acci√≥n: Monitorear tendencias en sus reviews. Si empiezan a acumularse quejas o elogios sobre aspectos espec√≠ficos, puede indicar un cambio en la percepci√≥n general.\")\n",
        "    print(\"  - Acci√≥n: Este cl√∫ster es una buena base para pruebas A/B o lanzamientos graduales de nuevos productos/caracter√≠sticas.\")\n",
        "    print(\"- **General (Basado en Errores del Modelo):**\")\n",
        "    print(\"  - Acci√≥n: Utilizar las reviews donde el modelo fall√≥ (FP y FN) como datos adicionales para refinar el modelo de clasificaci√≥n de sentimiento, prestando especial atenci√≥n al lenguaje usado en los cl√∫steres problem√°ticos.\")\n",
        "    print(\"  - Acci√≥n: Si la proporci√≥n de errores en un cl√∫ster particular es muy alta, considerar un an√°lisis m√°s profundo de las reviews en ese cl√∫ster para entender qu√© patrones de lenguaje o temas confunden al modelo.\")\n",
        "\n",
        "else:\n",
        "    print(\"No hay suficientes datos con cl√∫steres asignados y predicciones para analizar errores.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "z3pQ1S956h0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un \"embedding\" en NLP (Procesamiento del Lenguaje Natural) es una representaci√≥n vectorial densa de una palabra, frase o documento en un espacio de baja dimensi√≥n. En lugar de representar las palabras como s√≠mbolos discretos o √≠ndices (como en un vocabulario one-hot), un embedding asigna a cada unidad de texto un vector de n√∫meros reales.\n",
        "\n",
        "**Utilidad:** La principal utilidad de los embeddings radica en capturar relaciones sem√°nticas y sint√°cticas entre palabras o textos. Palabras con significados similares o que aparecen en contextos parecidos tienden a tener vectores de embedding cercanos en el espacio vectorial. Esto permite a los algoritmos de aprendizaje autom√°tico trabajar con texto de una manera que considera el significado, mejorando el rendimiento en tareas como clasificaci√≥n de texto, traducci√≥n autom√°tica, an√°lisis de sentimientos, b√∫squeda de similitud, etc., en comparaci√≥n con representaciones m√°s simples como el conteo de palabras."
      ],
      "metadata": {
        "id": "2GpTatdr6fvz"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}